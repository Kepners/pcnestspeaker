<!DOCTYPE html>
<html>
<head>
  <title>PC Nest Speaker - WebRTC Receiver</title>
  <script src="//www.gstatic.com/cast/sdk/libs/caf_receiver/v3/cast_receiver_framework.js"></script>
  <style>
    body { background: #334E58; margin: 0; padding: 0; }
    #player { position: absolute; width: 100%; height: 100%; }
    #status { color: #FCBFB7; font-family: sans-serif; font-size: 24px; text-align: center; padding-top: 40%; position: relative; z-index: 100; }
  </style>
</head>
<body>
  <cast-media-player id="player"></cast-media-player>
  <div id="status">PC Nest Speaker v2</div>
  <audio id="webrtc-audio" autoplay></audio>

  <script>
    const WEBRTC_NAMESPACE = 'urn:x-cast:com.pcnestspeaker.webrtc';

    // Cast framework setup
    const context = cast.framework.CastReceiverContext.getInstance();
    const playerManager = context.getPlayerManager();
    const playbackConfig = new cast.framework.PlaybackConfig();

    // Low latency settings for HTTP fallback
    playbackConfig.autoResumeDuration = 0;
    playbackConfig.autoPauseDuration = 0;
    playbackConfig.initialBandwidth = 100000000;
    playbackConfig.disablePreload = true;
    playbackConfig.autoResumeNumberOfSegments = 0;
    playbackConfig.shakaConfig = {
      streaming: {
        bufferingGoal: 0.1,
        rebufferingGoal: 0,
        bufferBehind: 0,
        lowLatencyMode: true,
        segmentPrefetchLimit: 0,
        retryParameters: { maxAttempts: 1, timeout: 1000 }
      }
    };

    playerManager.setMessageInterceptor(
      cast.framework.messages.MessageType.PRELOAD,
      () => null
    );

    playerManager.setPlaybackConfig(playbackConfig);

    // ===================
    // WebRTC via MediaMTX WHEP (WebRTC-HTTP Egress Protocol)
    // Much simpler than webrtc-streamer - just POST offer, get answer
    // ===================
    let peerConnection = null;
    let whepResourceUrl = null;  // URL returned by WHEP for session management
    const audioElement = document.getElementById('webrtc-audio');

    function log(msg) {
      console.log('[WebRTC] ' + msg);
      document.getElementById('status').textContent = msg;
    }

    // Hide default media player when using WebRTC
    function hideDefaultPlayer() {
      const player = document.getElementById('player');
      if (player) player.style.display = 'none';
    }

    /**
     * Connect to MediaMTX server via WHEP protocol
     * WHEP endpoint: {serverUrl}/pcaudio/whep
     */
    async function connectToMediaMTX(serverUrl, streamName = 'pcaudio') {
      log('Connecting to MediaMTX...');

      // ICE configuration - STUN + TURN for NAT traversal
      // TURN required for symmetric NAT on Cast devices (Android TV, Nest)
      const iceConfig = {
        iceServers: [
          { urls: 'stun:stun.l.google.com:19302' },
          { urls: 'stun:stun1.l.google.com:19302' },
          {
            urls: 'turn:openrelay.metered.ca:80',
            username: 'openrelayproject',
            credential: 'openrelayproject'
          },
          {
            urls: 'turn:openrelay.metered.ca:443',
            username: 'openrelayproject',
            credential: 'openrelayproject'
          },
          {
            urls: 'turn:openrelay.metered.ca:443?transport=tcp',
            username: 'openrelayproject',
            credential: 'openrelayproject'
          }
        ]
      };

      peerConnection = new RTCPeerConnection(iceConfig);
      log('PeerConnection created');

      // Handle incoming audio track
      peerConnection.ontrack = (event) => {
        log('Track received: ' + event.track.kind);
        console.log('[WebRTC] Track event:', event);
        console.log('[WebRTC] Track:', event.track);
        console.log('[WebRTC] Streams:', event.streams);

        if (event.track.kind === 'audio') {
          log('Audio track: ' + event.track.id);
          if (event.streams && event.streams[0]) {
            audioElement.srcObject = event.streams[0];
            log('Stream attached to audio element');

            // Try to play with user gesture workaround
            audioElement.muted = false;
            audioElement.volume = 1.0;

            audioElement.play().then(() => {
              log('Playing! Vol=' + audioElement.volume);
            }).catch(e => {
              log('Play error: ' + e.message);
              // Try muted first then unmute (autoplay workaround)
              audioElement.muted = true;
              audioElement.play().then(() => {
                log('Playing muted, unmuting...');
                setTimeout(() => {
                  audioElement.muted = false;
                  log('Unmuted! Vol=' + audioElement.volume);
                }, 100);
              }).catch(e2 => log('Muted play failed: ' + e2.message));
            });
          } else {
            log('No streams in track event!');
            // Try using track directly
            const stream = new MediaStream([event.track]);
            audioElement.srcObject = stream;
            audioElement.play().catch(e => log('Direct track play error: ' + e.message));
          }
        }
      };

      peerConnection.onconnectionstatechange = () => {
        const state = peerConnection.connectionState;
        log('Connection: ' + state);
        if (state === 'connected') {
          log('WebRTC Connected!');
        } else if (state === 'failed') {
          log('Connection failed - retrying...');
          // Auto-retry on failure
          setTimeout(() => {
            disconnect();
            connectToMediaMTX(serverUrl, streamName);
          }, 3000);
        }
      };

      peerConnection.oniceconnectionstatechange = () => {
        log('ICE: ' + peerConnection.iceConnectionState);
      };

      // Add transceiver to receive audio (recvonly)
      peerConnection.addTransceiver('audio', { direction: 'recvonly' });

      // Create SDP offer
      const offer = await peerConnection.createOffer();
      await peerConnection.setLocalDescription(offer);
      log('Created offer');

      // Wait for ICE gathering to complete (or timeout after 2s)
      await new Promise((resolve) => {
        if (peerConnection.iceGatheringState === 'complete') {
          resolve();
        } else {
          const checkState = () => {
            if (peerConnection.iceGatheringState === 'complete') {
              peerConnection.removeEventListener('icegatheringstatechange', checkState);
              resolve();
            }
          };
          peerConnection.addEventListener('icegatheringstatechange', checkState);
          // Timeout after 2 seconds
          setTimeout(resolve, 2000);
        }
      });

      log('ICE gathering complete');

      // Send offer to MediaMTX WHEP endpoint
      const whepUrl = serverUrl + '/' + streamName + '/whep';
      log('WHEP URL: ' + whepUrl);

      try {
        log('Fetching: ' + whepUrl);
        const response = await fetch(whepUrl, {
          method: 'POST',
          mode: 'cors',
          headers: {
            'Content-Type': 'application/sdp'
          },
          body: peerConnection.localDescription.sdp
        });

        log('Response status: ' + response.status);

        if (!response.ok) {
          const errorText = await response.text();
          throw new Error('WHEP error ' + response.status + ': ' + errorText);
        }

        // Get resource URL for session management (DELETE to stop)
        const location = response.headers.get('Location');
        if (location) {
          // Handle relative URLs
          if (location.startsWith('/')) {
            whepResourceUrl = serverUrl + location;
          } else {
            whepResourceUrl = location;
          }
          log('Session URL: ' + whepResourceUrl);
        }

        // Get SDP answer
        const answerSdp = await response.text();
        log('Got SDP answer');

        // Set remote description
        await peerConnection.setRemoteDescription({
          type: 'answer',
          sdp: answerSdp
        });
        log('Set remote description');

      } catch (e) {
        log('Error: ' + e.name + ': ' + e.message);
        console.error('WHEP error details:', e);
        console.error('Error name:', e.name);
        console.error('Error message:', e.message);
        console.error('Error stack:', e.stack);
      }
    }

    function disconnect() {
      if (peerConnection) {
        // Send DELETE to WHEP resource URL to clean up server-side
        if (whepResourceUrl) {
          fetch(whepResourceUrl, {
            method: 'DELETE',
            headers: { 'bypass-tunnel-reminder': 'true' }
          }).catch(() => {});
          whepResourceUrl = null;
        }
        peerConnection.close();
        peerConnection = null;
        audioElement.srcObject = null;
        log('Disconnected');
      }
    }

    // Handle Cast messages (for starting/stopping WebRTC)
    function handleMessage(event) {
      log('Message: ' + JSON.stringify(event.data));
      const data = event.data;

      switch (data.type) {
        case 'connect':
          if (data.url) {
            connectToMediaMTX(data.url, data.stream || 'pcaudio');
          } else {
            log('Error: No URL provided');
          }
          break;
        case 'disconnect':
        case 'close':
          disconnect();
          break;
        default:
          log('Unknown: ' + data.type);
      }
    }

    // Register custom message handler
    context.addCustomMessageListener(WEBRTC_NAMESPACE, handleMessage);

    // CRITICAL: Set up LOAD interceptor BEFORE context.start()
    // This intercepts all media load requests to check for WebRTC URLs
    playerManager.setMessageInterceptor(
      cast.framework.messages.MessageType.LOAD,
      (request) => {
        log('LOAD intercepted');

        // Method 1: Check contentId for webrtc:// prefix (most reliable)
        // Format: webrtc://actual-https-url/path
        if (request.media && request.media.contentId) {
          const contentId = request.media.contentId;
          log('contentId: ' + contentId);

          if (contentId.startsWith('webrtc://')) {
            // Extract the actual HTTPS URL from webrtc://https://example.com/path
            const httpsUrl = contentId.replace('webrtc://', '');
            log('WebRTC URL: ' + httpsUrl);
            hideDefaultPlayer();  // Hide default media player UI
            connectToMediaMTX(httpsUrl, 'pcaudio');
            return null;  // Cancel default media player
          }
        }

        // Method 2: Check media.customData
        if (request.media && request.media.customData) {
          log('customData: ' + JSON.stringify(request.media.customData));
          if (request.media.customData.webrtcUrl) {
            log('WebRTC URL: ' + request.media.customData.webrtcUrl);
            connectToMediaMTX(request.media.customData.webrtcUrl, request.media.customData.stream || 'pcaudio');
            return null;
          }
        }

        // Method 3: Check root-level customData
        if (request.customData && request.customData.webrtcUrl) {
          log('WebRTC URL: ' + request.customData.webrtcUrl);
          connectToMediaMTX(request.customData.webrtcUrl, request.customData.stream || 'pcaudio');
          return null;
        }

        // Not WebRTC - handle as regular media
        log('Regular media: ' + (request.media ? request.media.contentId : 'none'));
        if (request.media) {
          request.media.streamType = cast.framework.messages.StreamType.LIVE;
          request.autoplay = true;
          request.currentTime = 0;
        }
        return request;
      }
    );

    // Start receiver (AFTER interceptor is set up)
    context.start({
      playbackConfig: playbackConfig,
      skipPlayersLoad: false,
      disableIdleTimeout: true,
      supportedCommands: cast.framework.messages.Command.ALL_BASIC_MEDIA,
      customNamespaces: {
        [WEBRTC_NAMESPACE]: cast.framework.system.MessageType.JSON
      }
    });

    log('Ready - Waiting for URL...');
  </script>
</body>
</html>
