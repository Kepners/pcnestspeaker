<!DOCTYPE html>
<html>
<head>
  <title>PC Nest Speaker - WebRTC Receiver</title>
  <script src="//www.gstatic.com/cast/sdk/libs/caf_receiver/v3/cast_receiver_framework.js"></script>
  <style>
    body { background: #334E58; margin: 0; padding: 0; }
    #player { position: absolute; width: 100%; height: 100%; }
    #status { color: #FCBFB7; font-family: sans-serif; font-size: 24px; text-align: center; padding-top: 40%; position: relative; z-index: 100; }
  </style>
</head>
<body>
  <cast-media-player id="player"></cast-media-player>
  <div id="status">PC Nest Speaker v3</div>
  <audio id="webrtc-audio" autoplay></audio>

  <script>
    const WEBRTC_NAMESPACE = 'urn:x-cast:com.pcnestspeaker.webrtc';

    // Cast framework setup
    const context = cast.framework.CastReceiverContext.getInstance();
    const playerManager = context.getPlayerManager();
    const playbackConfig = new cast.framework.PlaybackConfig();

    // Low latency settings for HTTP fallback
    playbackConfig.autoResumeDuration = 0;
    playbackConfig.autoPauseDuration = 0;
    playbackConfig.initialBandwidth = 100000000;
    playbackConfig.disablePreload = true;
    playbackConfig.autoResumeNumberOfSegments = 0;
    playbackConfig.shakaConfig = {
      streaming: {
        bufferingGoal: 0.1,
        rebufferingGoal: 0,
        bufferBehind: 0,
        lowLatencyMode: true,
        segmentPrefetchLimit: 0,
        retryParameters: { maxAttempts: 1, timeout: 1000 }
      }
    };

    playerManager.setMessageInterceptor(
      cast.framework.messages.MessageType.PRELOAD,
      () => null
    );

    playerManager.setPlaybackConfig(playbackConfig);

    // ===================
    // WebRTC via PROXY SIGNALING (no direct HTTP fetch from receiver!)
    // PC proxies WHEP requests to avoid mixed content issues
    // ===================
    let peerConnection = null;
    let currentStreamName = 'pcaudio';
    const audioElement = document.getElementById('webrtc-audio');

    function log(msg) {
      console.log('[WebRTC] ' + msg);
      document.getElementById('status').textContent = msg;
    }

    // Send message back to PC via custom namespace
    function sendToPC(data) {
      log('Sending to PC: ' + data.type);
      console.log('[WebRTC] Sending:', data);
      context.sendCustomMessage(WEBRTC_NAMESPACE, undefined, data);
    }

    // Hide default media player when using WebRTC
    function hideDefaultPlayer() {
      const player = document.getElementById('player');
      if (player) player.style.display = 'none';
    }

    /**
     * Create PeerConnection and generate SDP offer
     * The offer is sent back to PC, which proxies it to MediaMTX WHEP
     */
    async function createOfferForProxy(streamName = 'pcaudio') {
      log('Creating WebRTC offer...');
      currentStreamName = streamName;

      // ICE configuration with Google STUN server
      const iceConfig = {
        iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
      };

      peerConnection = new RTCPeerConnection(iceConfig);
      log('PeerConnection created');

      // Handle incoming audio track
      peerConnection.ontrack = (event) => {
        log('Track received: ' + event.track.kind);
        console.log('[WebRTC] Track event:', event);

        if (event.track.kind === 'audio') {
          log('Audio track: ' + event.track.id);
          if (event.streams && event.streams[0]) {
            audioElement.srcObject = event.streams[0];
            log('Stream attached');

            audioElement.muted = false;
            audioElement.volume = 1.0;

            audioElement.play().then(() => {
              log('Playing! Vol=' + audioElement.volume);
            }).catch(e => {
              log('Play error: ' + e.message);
              // Autoplay workaround
              audioElement.muted = true;
              audioElement.play().then(() => {
                log('Playing muted, unmuting...');
                setTimeout(() => {
                  audioElement.muted = false;
                  log('Unmuted! Vol=' + audioElement.volume);
                }, 100);
              }).catch(e2 => log('Muted play failed: ' + e2.message));
            });
          } else {
            log('No streams in track event!');
            const stream = new MediaStream([event.track]);
            audioElement.srcObject = stream;
            audioElement.play().catch(e => log('Direct track play error: ' + e.message));
          }
        }
      };

      peerConnection.onconnectionstatechange = () => {
        const state = peerConnection.connectionState;
        log('Connection: ' + state);
        if (state === 'connected') {
          log('WebRTC Connected!');
        } else if (state === 'failed') {
          log('Connection failed');
          sendToPC({ type: 'connection_failed' });
        }
      };

      peerConnection.oniceconnectionstatechange = () => {
        log('ICE: ' + peerConnection.iceConnectionState);
      };

      // Add transceiver to receive audio (recvonly)
      peerConnection.addTransceiver('audio', { direction: 'recvonly' });

      // Create SDP offer
      const offer = await peerConnection.createOffer();
      await peerConnection.setLocalDescription(offer);
      log('Created offer');

      // Wait for ICE gathering to complete (or timeout after 2s)
      await new Promise((resolve) => {
        if (peerConnection.iceGatheringState === 'complete') {
          resolve();
        } else {
          const checkState = () => {
            if (peerConnection.iceGatheringState === 'complete') {
              peerConnection.removeEventListener('icegatheringstatechange', checkState);
              resolve();
            }
          };
          peerConnection.addEventListener('icegatheringstatechange', checkState);
          setTimeout(resolve, 2000);
        }
      });

      log('ICE gathering complete');

      // Send offer to PC for proxy to MediaMTX
      sendToPC({
        type: 'offer',
        sdp: peerConnection.localDescription.sdp,
        stream: streamName
      });

      log('Offer sent to PC');
    }

    /**
     * Handle SDP answer from PC (proxied from MediaMTX)
     */
    async function handleAnswerFromPC(answerSdp) {
      log('Received answer from PC');

      if (!peerConnection) {
        log('Error: No PeerConnection!');
        return;
      }

      try {
        await peerConnection.setRemoteDescription({
          type: 'answer',
          sdp: answerSdp
        });
        log('Set remote description');
      } catch (e) {
        log('Error setting answer: ' + e.message);
        console.error('Answer error:', e);
      }
    }

    /**
     * Legacy: Connect to MediaMTX directly via WHEP (may fail due to mixed content)
     * Kept for fallback/testing
     */
    async function connectToMediaMTX(serverUrl, streamName = 'pcaudio') {
      log('Connecting to MediaMTX...');

      const iceConfig = {
        iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
      };

      peerConnection = new RTCPeerConnection(iceConfig);
      log('PeerConnection created');

      peerConnection.ontrack = (event) => {
        log('Track received: ' + event.track.kind);
        if (event.track.kind === 'audio') {
          log('Audio track: ' + event.track.id);
          if (event.streams && event.streams[0]) {
            audioElement.srcObject = event.streams[0];
            audioElement.muted = false;
            audioElement.volume = 1.0;
            audioElement.play().then(() => {
              log('Playing! Vol=' + audioElement.volume);
            }).catch(e => {
              log('Play error: ' + e.message);
              audioElement.muted = true;
              audioElement.play().then(() => {
                setTimeout(() => { audioElement.muted = false; }, 100);
              });
            });
          }
        }
      };

      peerConnection.onconnectionstatechange = () => {
        log('Connection: ' + peerConnection.connectionState);
      };

      peerConnection.addTransceiver('audio', { direction: 'recvonly' });

      const offer = await peerConnection.createOffer();
      await peerConnection.setLocalDescription(offer);
      log('Created offer');

      await new Promise((resolve) => {
        if (peerConnection.iceGatheringState === 'complete') resolve();
        else {
          peerConnection.addEventListener('icegatheringstatechange', () => {
            if (peerConnection.iceGatheringState === 'complete') resolve();
          });
          setTimeout(resolve, 2000);
        }
      });

      const whepUrl = serverUrl + '/' + streamName + '/whep';
      log('WHEP URL: ' + whepUrl);

      try {
        const response = await fetch(whepUrl, {
          method: 'POST',
          mode: 'cors',
          headers: { 'Content-Type': 'application/sdp' },
          body: peerConnection.localDescription.sdp
        });

        if (!response.ok) {
          throw new Error('WHEP error ' + response.status);
        }

        const answerSdp = await response.text();
        await peerConnection.setRemoteDescription({ type: 'answer', sdp: answerSdp });
        log('Connected via direct WHEP');

      } catch (e) {
        log('Direct WHEP failed: ' + e.message);
        // Tell PC to use proxy signaling instead
        sendToPC({ type: 'whep_failed', error: e.message });
      }
    }

    function disconnect() {
      if (peerConnection) {
        peerConnection.close();
        peerConnection = null;
        audioElement.srcObject = null;
        log('Disconnected');
      }
    }

    // Handle Cast messages
    function handleMessage(event) {
      log('Message: ' + JSON.stringify(event.data));
      const data = event.data;

      switch (data.type) {
        case 'connect':
          // Legacy: Direct WHEP connection (may fail due to mixed content)
          if (data.url) {
            hideDefaultPlayer();
            connectToMediaMTX(data.url, data.stream || 'pcaudio');
          } else {
            log('Error: No URL provided');
          }
          break;

        case 'request_offer':
          // NEW: Proxy signaling - PC requests us to generate offer
          hideDefaultPlayer();
          createOfferForProxy(data.stream || 'pcaudio');
          break;

        case 'answer':
          // NEW: PC sends us the SDP answer (proxied from MediaMTX)
          if (data.sdp) {
            handleAnswerFromPC(data.sdp);
          } else {
            log('Error: No SDP in answer');
          }
          break;

        case 'ice_candidate':
          // Handle ICE candidate from PC (if trickle ICE is needed)
          if (peerConnection && data.candidate) {
            peerConnection.addIceCandidate(new RTCIceCandidate(data.candidate))
              .catch(e => log('ICE error: ' + e.message));
          }
          break;

        case 'disconnect':
        case 'close':
          disconnect();
          break;

        default:
          log('Unknown: ' + data.type);
      }
    }

    // Register custom message handler
    context.addCustomMessageListener(WEBRTC_NAMESPACE, handleMessage);

    // CRITICAL: Set up LOAD interceptor BEFORE context.start()
    playerManager.setMessageInterceptor(
      cast.framework.messages.MessageType.LOAD,
      (request) => {
        log('LOAD intercepted');

        if (request.media && request.media.contentId) {
          const contentId = request.media.contentId;
          log('contentId: ' + contentId);

          if (contentId.startsWith('webrtc://')) {
            const httpsUrl = contentId.replace('webrtc://', '');
            log('WebRTC URL: ' + httpsUrl);
            hideDefaultPlayer();
            connectToMediaMTX(httpsUrl, 'pcaudio');
            return null;
          }
        }

        if (request.media && request.media.customData && request.media.customData.webrtcUrl) {
          hideDefaultPlayer();
          connectToMediaMTX(request.media.customData.webrtcUrl, request.media.customData.stream || 'pcaudio');
          return null;
        }

        if (request.customData && request.customData.webrtcUrl) {
          hideDefaultPlayer();
          connectToMediaMTX(request.customData.webrtcUrl, request.customData.stream || 'pcaudio');
          return null;
        }

        log('Regular media: ' + (request.media ? request.media.contentId : 'none'));
        if (request.media) {
          request.media.streamType = cast.framework.messages.StreamType.LIVE;
          request.autoplay = true;
          request.currentTime = 0;
        }
        return request;
      }
    );

    // Start receiver
    context.start({
      playbackConfig: playbackConfig,
      skipPlayersLoad: false,
      disableIdleTimeout: true,
      supportedCommands: cast.framework.messages.Command.ALL_BASIC_MEDIA,
      customNamespaces: {
        [WEBRTC_NAMESPACE]: cast.framework.system.MessageType.JSON
      }
    });

    log('Ready - v3 Proxy Signaling');
  </script>
</body>
</html>
